{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77959b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bf444",
   "metadata": {},
   "source": [
    "## Generate our data given by the Lorenz equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a1af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Lorenz system's derivative function\n",
    "def lorenz_deriv(x_y_z, t0, sigma=10, beta=8/3, rho=28):\n",
    "    x, y, z = x_y_z\n",
    "    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "# Generate data for a given rho value\n",
    "def generate_data(rho, seed=123):\n",
    "    dt = 0.01\n",
    "    T = 8\n",
    "    t = np.arange(0, T + dt, dt)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t, args=(10, 8/3, rho)) for x0_j in x0])\n",
    "\n",
    "    nn_input = np.zeros((100 * (len(t) - 1), 3))\n",
    "    nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "    for j in range(100):\n",
    "        nn_input[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, :-1, :]\n",
    "        nn_output[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, 1:, :]\n",
    "\n",
    "    return nn_input, nn_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44a3f8",
   "metadata": {},
   "source": [
    "## Train a NN to advance the solution from t to t + ∆t for ρ = 10, 28 and 40 (Also define the training functions for LSTM, RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c6a36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Feed-Forward Neural Network\n",
    "def train_ffnn(X_train, y_train, X_val, y_val, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=(3,)))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=0)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Train a Recurrent Neural Network\n",
    "def train_rnn(X_train, y_train, X_val, y_val, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(64, activation='tanh', input_shape=(1, 3), return_sequences=True))\n",
    "    model.add(SimpleRNN(64, activation='tanh'))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    # Reshape the validation data\n",
    "    X_val_rnn = X_val.reshape(-1, 1, 3)\n",
    "    y_val_rnn = y_val.reshape(-1, 1, 3)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val_rnn, y_val_rnn), verbose=0)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# Train a Long Short-Term Memory Network\n",
    "def train_lstm(X_train, y_train, X_val, y_val, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='tanh', input_shape=(1, 3), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='tanh'))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    # Reshape the validation data\n",
    "    X_val_lstm = X_val.reshape(-1, 1, 3)\n",
    "    y_val_lstm = y_val.reshape(-1, 1, 3)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val_lstm, y_val_lstm), verbose=0)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630ad1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data for rho = 10, 28, 40\n",
    "rho_values = [10, 28, 40]\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []\n",
    "\n",
    "for rho in rho_values:\n",
    "    X, y = generate_data(rho)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    X_train_list.append(X_train)\n",
    "    y_train_list.append(y_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_combined = np.vstack(X_train_list)\n",
    "y_train_combined = np.vstack(y_train_list)\n",
    "\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = scaler.fit_transform(y_train_combined)\n",
    "\n",
    "# Train FFNN, RNN, LSTM, and ESN\n",
    "X_train_rnn_lstm = X_train_combined.reshape(-1, 1, 3)\n",
    "y_train_rnn_lstm = y_train_combined.reshape(-1, 1, 3)\n",
    "\n",
    "ffnn_model, _ = train_ffnn(X_train_combined, y_train_combined, X_test_list[0], y_test_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29299c0",
   "metadata": {},
   "source": [
    "## Now see how well NN works for future state prediction for ρ = 17 and ρ = 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9930ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 609us/step\n",
      "Mean Squared Error for rho = 17\n",
      "FFNN: 2.7239888884449422e-05\n",
      "2500/2500 [==============================] - 1s 588us/step\n",
      "Mean Squared Error for rho = 35\n",
      "FFNN: 3.200739952980744e-05\n"
     ]
    }
   ],
   "source": [
    "# Test the models for rho = 17 and rho = 35\n",
    "rho_test_values = [17, 35]\n",
    "for rho in rho_test_values:\n",
    "    X_test, y_test = generate_data(rho)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "    X_test_rnn_lstm = X_test_scaled.reshape(-1, 1, 3)\n",
    "\n",
    "    ffnn_pred = ffnn_model.predict(X_test_scaled)\n",
    "    # Calculate Mean Squared Error (MSE) for each model\n",
    "    ffnn_mse = np.mean((y_test_scaled - ffnn_pred)**2)\n",
    "\n",
    "    print(f\"Mean Squared Error for rho = {rho}\")\n",
    "    print(f\"FFNN: {ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0a03c",
   "metadata": {},
   "source": [
    "## Compare feed-forward, LSTM, RNN and Echo State Networks for forecasting the dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "557d6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model, _ = train_rnn(X_train_rnn_lstm, y_train_rnn_lstm, X_test_list[0], y_test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c8ced28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 734us/step\n",
      "Mean Squared Error for rho = 17\n",
      "RNN: 0.029654276073139786\n",
      "2500/2500 [==============================] - 2s 794us/step\n",
      "Mean Squared Error for rho = 35\n",
      "RNN: 0.06490629807612544\n"
     ]
    }
   ],
   "source": [
    "for rho in rho_test_values:\n",
    "    X_test, y_test = generate_data(rho)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "    X_test_rnn_lstm = X_test_scaled.reshape(-1, 1, 3)\n",
    "\n",
    "    rnn_pred = rnn_model.predict(X_test_rnn_lstm)\n",
    "    # Calculate Mean Squared Error (MSE) for each model\n",
    "    rnn_mse = np.mean((y_test_scaled - rnn_pred)**2)\n",
    "\n",
    "    print(f\"Mean Squared Error for rho = {rho}\")\n",
    "    print(f\"RNN: {rnn_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3feac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model, _ = train_lstm(X_train_rnn_lstm, y_train_rnn_lstm, X_test_list[0], y_test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50a60939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 3s 965us/step\n",
      "Mean Squared Error for rho = 17\n",
      "LSTM: 0.030265745313244153\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "Mean Squared Error for rho = 35\n",
      "LSTM: 0.06378890443500634\n"
     ]
    }
   ],
   "source": [
    "for rho in rho_test_values:\n",
    "    X_test, y_test = generate_data(rho)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "    X_test_rnn_lstm = X_test_scaled.reshape(-1, 1, 3)\n",
    "\n",
    "    lstm_pred = lstm_model.predict(X_test_rnn_lstm)\n",
    "    # Calculate Mean Squared Error (MSE) for each model\n",
    "    lstm_mse = np.mean((y_test_scaled - lstm_pred)**2)\n",
    "\n",
    "    print(f\"Mean Squared Error for rho = {rho}\")\n",
    "    print(f\"LSTM: {lstm_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0b43b",
   "metadata": {},
   "source": [
    "## Create our ESN model we can use to forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58ed2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our ESN model for comparison\n",
    "def create_esn_model(input_shape, units, connectivity=0.1, leaky=1, spectral_radius=0.9):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    esn_outputs = tfa.layers.ESN(units, connectivity, leaky, spectral_radius)(inputs)\n",
    "    output = tf.keras.layers.Dense(1)(esn_outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_esn(X_train, y_train, X_test, y_test, input_shape, reservoir_size, epochs=50, batch_size=32):\n",
    "    esn_model = create_esn_model(input_shape, reservoir_size)\n",
    "    esn_history = esn_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "    return esn_model, esn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcfb6bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 43.1427 - 6s/epoch - 861us/step\n",
      "Epoch 2/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 43.1147 - 6s/epoch - 919us/step\n",
      "Epoch 3/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.8748 - 6s/epoch - 952us/step\n",
      "Epoch 4/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 43.4141 - 6s/epoch - 855us/step\n",
      "Epoch 5/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.5196 - 6s/epoch - 900us/step\n",
      "Epoch 6/50\n",
      "6750/6750 - 5s - loss: 0.0420 - val_loss: 42.0645 - 5s/epoch - 811us/step\n",
      "Epoch 7/50\n",
      "6750/6750 - 5s - loss: 0.0420 - val_loss: 42.7282 - 5s/epoch - 795us/step\n",
      "Epoch 8/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.6322 - 6s/epoch - 835us/step\n",
      "Epoch 9/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.6245 - 6s/epoch - 909us/step\n",
      "Epoch 10/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 42.1967 - 7s/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.1018 - 6s/epoch - 897us/step\n",
      "Epoch 12/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.6265 - 6s/epoch - 908us/step\n",
      "Epoch 13/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 42.4549 - 7s/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.0801 - 6s/epoch - 852us/step\n",
      "Epoch 15/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.5777 - 6s/epoch - 960us/step\n",
      "Epoch 16/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.6967 - 6s/epoch - 955us/step\n",
      "Epoch 17/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.8380 - 6s/epoch - 914us/step\n",
      "Epoch 18/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 42.2613 - 7s/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.9231 - 7s/epoch - 980us/step\n",
      "Epoch 20/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 42.4090 - 6s/epoch - 915us/step\n",
      "Epoch 21/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.6477 - 7s/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.9729 - 6s/epoch - 901us/step\n",
      "Epoch 23/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.6863 - 6s/epoch - 932us/step\n",
      "Epoch 24/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.8401 - 7s/epoch - 987us/step\n",
      "Epoch 25/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.8289 - 6s/epoch - 879us/step\n",
      "Epoch 26/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.5094 - 7s/epoch - 980us/step\n",
      "Epoch 27/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.9026 - 6s/epoch - 946us/step\n",
      "Epoch 28/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.3482 - 6s/epoch - 879us/step\n",
      "Epoch 29/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.7641 - 7s/epoch - 990us/step\n",
      "Epoch 30/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.4145 - 6s/epoch - 891us/step\n",
      "Epoch 31/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.5347 - 6s/epoch - 922us/step\n",
      "Epoch 32/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.3689 - 7s/epoch - 991us/step\n",
      "Epoch 33/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.6939 - 6s/epoch - 934us/step\n",
      "Epoch 34/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.0601 - 7s/epoch - 972us/step\n",
      "Epoch 35/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.5157 - 6s/epoch - 958us/step\n",
      "Epoch 36/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.1789 - 6s/epoch - 856us/step\n",
      "Epoch 37/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 40.9625 - 7s/epoch - 992us/step\n",
      "Epoch 38/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.5877 - 6s/epoch - 894us/step\n",
      "Epoch 39/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.3620 - 6s/epoch - 847us/step\n",
      "Epoch 40/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.2713 - 7s/epoch - 979us/step\n",
      "Epoch 41/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.1844 - 6s/epoch - 898us/step\n",
      "Epoch 42/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 40.8029 - 7s/epoch - 996us/step\n",
      "Epoch 43/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 40.8942 - 6s/epoch - 947us/step\n",
      "Epoch 44/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.6648 - 6s/epoch - 896us/step\n",
      "Epoch 45/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 40.8982 - 7s/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 41.0280 - 6s/epoch - 903us/step\n",
      "Epoch 47/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 40.8370 - 6s/epoch - 916us/step\n",
      "Epoch 48/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 41.0482 - 7s/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "6750/6750 - 6s - loss: 0.0420 - val_loss: 40.9790 - 6s/epoch - 857us/step\n",
      "Epoch 50/50\n",
      "6750/6750 - 7s - loss: 0.0420 - val_loss: 40.7614 - 7s/epoch - 964us/step\n"
     ]
    }
   ],
   "source": [
    "X_train_esn = X_train_combined.reshape(-1, 1, X_train_combined.shape[1])\n",
    "X_test_esn = X_test_list[0].reshape(-1, 1, X_test_list[0].shape[1])\n",
    "y_test_esn = y_test_list[0].reshape(-1, 1, y_test_list[0].shape[1])\n",
    "\n",
    "esn_model, esn_history = train_esn(X_train_esn, y_train_combined, X_test_esn, y_test_esn, input_shape, reservoir_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dd3f3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 2s 657us/step\n",
      "Mean Squared Error for rho = 17\n",
      "ESN: 0.04059388705881501\n",
      "2500/2500 [==============================] - 2s 649us/step\n",
      "Mean Squared Error for rho = 35\n",
      "ESN: 0.027737173186624834\n"
     ]
    }
   ],
   "source": [
    "for rho in rho_test_values:\n",
    "    X_test, y_test = generate_data(rho)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "    X_test_esn = X_test_scaled.reshape(-1, 1, 3)\n",
    "\n",
    "    esn_pred = esn_model.predict(X_test_esn)\n",
    "    esn_mse = np.mean((y_test_scaled - esn_pred)**2)\n",
    "\n",
    "    print(f\"Mean Squared Error for rho = {rho}\")\n",
    "    print(f\"ESN: {esn_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10317d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
